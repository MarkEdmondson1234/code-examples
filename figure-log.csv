"filename","caption","fig_num"
"gcp-pyramid.png","Google Cloud Platform Pyramid Hierarchy on which service you should choose for your applications","01-01"
"data-architecture-7.png","Data Architecture for the Predictive Audiences use case:  website data is sent to Google Analytics 4 which creates the predictive audience that is then exported to Google Ads","01-02"
"chapter8_predictive.drawio.png","Data Architecture for the User Segmentation use case","01-03"
"data-architecture-chapter_09.png","Real-time data is taken from GA4 and a forecast is created to inform employee what content they should prioritise for social media content and on-site banners via Google Optimise","01-04"
"storage-decision-tree.png","A flowchart decision tree on selecting the correct GCP storage option","02-01"
"enhanced-measurement-03.png","","03-01"
"ga4-custom-event-parameters.png","Custom events and their parameters.  As well as the custom parameters you send in, GA4 also collects useful data points such as ga_session_id and page_location","03-02"
"gtm-setup-ga4-article_read.png","A suggested GTM setting for sending a GA4 custom event: article_read","03-03"
"gtm-dom-selector-webpage.png","The blog post's publish date is available in the page HTML.  Using your web browser's console you can find the CSS selector to pick up that data for use within Google Tag Manager","03-04"
"gtm-dom-selector.png","The CSS code for the data can be used within Google Tag Manager's DOM Element Variable for use with GA4 and other tags","03-05"
"ga4-custom-dimension-config.png","Configuring a custom dimension from the new parameter created with the article_read event","03-06"
"simo-base-example-gtag-get-api.jpg","Write Client ID And Other GTAG Fields Into dataLayer","03-07"
"messy-event-category-03.png","The article_read event contains a category parameter that has messy data due to multiple tags being recorded","03-08"
"creating-r-viewer-03.png","Creating a custom event based off data captured via other events - in this case r_viewer is derived from the article_read event.","03-09"
"created-events-list-03.png","Several created events based off of the custom category parameter from article_read","03-10"
"mark-as-npa.png","Marking a use property as NPA to avoid it being used in targeting audiences","03-11"
"cookieinfo-gtm-permissions.png","Permissions for the template code","03-12"
"gtm-variable-template-instance.png","Creating a variable from the template","03-13"
"gtm-consent-user-setup.png","Using the consent variable in a GA4 Event tag","03-14"
"user_consent_setup.png","Setting up a user consent parameter in GA4","03-15"
"event_consent_setup.png","Setting up an event consent parameter in GA4","03-16"
"mp_sequence_diagram.png","","03-17"
"ga4-bigquery-link.png","An example of a completed linking to BigQuery from the GA4 configuration screen","03-18"
"ga4-bigquery-sql-example-1-result.png","An example result for running the BigQuery SQL on your GA4 exports from","03-19"
"gcs-lifecycle-rules.png","Google Cloud Storage Lifecycle rules","03-20"
"cloud-function-gcs-trigger-1.png","Creating a Cloud Function to trigger from a newly uploaded file in Cloud Storage","03-21"
"cloud-function-gcs-trigger-2.png","Creating a Cloud Function to trigger from a newly uploaded file in Cloud Storage","03-22"
"cloud-function-gcs-code-1.png","Adding code for Python Cloud Functions","03-23"
"gcs-to-bq-logs1.png","Inspecting the Cloud Function logs we can see one file was imported to a specified schema, one used auto-detection","03-24"
"gcs-to-bq-logs2.png","Inspecting the BigQuery logs to see the schema has been specified as expected","03-25"
"gcs-to-bq-loaded.png","The BigQuery tables are imported from the CSV on Cloud Storage with the specified schema","03-26"
"cloud-build-setup-2.png","Linking Cloud Build to the GitHub repository holding your files","03-27"
"cloud-build-setup-3.png","A Cloud Build trigger that will activate the contents of the cloudbuild.yaml upon each commit to the GitHub repository","03-28"
"cloud-build-setup-4.png","Setting the Cloud Build permission to deploy Cloud Functions","03-29"
"cloud-build-setup-1.png","Files in a folder enabled for git","03-30"
"cloud-build-setup-5.png","A successful deployment of a Cloud Function via Cloud Build","03-31"
"tidy-1.png","Following three rules makes a dataset tidy: variables are in columns, observations are in rows, and values are in cells. From *R for Data Science* by Hadley Wickham and Garret Grolemund","04-01"
"bigquery-ga4-exports-logs.png","A Cloud Logging filter for seeing when your GA4 BigQuery exports are ready. We shall use this to create a PubSub topic.","04-02"
"bigquery-ga4-export-pubsub.png","Setting up your GA4 BigQuery log so it sends the entries to PubSub topic named ga4-bigquery","04-03"
"cloud-storage-example.png","Files sitting within Cloud Storage in its WebUI","04-04"
"cloud-storage-metadata.png","Various metadata associated with a file upload to Google Cloud Storage","04-05"
"bigquery-scheduler.png","Setting up the query into a scheduled query","04-06"
"airflow_dags.png","An example of an Airflow DAG.","04-07"
"airflow-example-dag.png","An example of the DAG created in Airflow","04-08"
"cloud-scheduler-list.png","Some Cloud Schedulers I have enabled for some tasks within my own Google Cloud Project","04-09"
"cloud-build-log-example.png","A Cloud Build that has successfully built within the Google Cloud Console.","04-10"
"bigquery-ga4-export-build-trigger.png","Setting up a Build Trigger that will build once the BigQuery export for GA4 is complete","04-11"
"bigquery-ga4-export-build-permissions.png","Adding to the Cloud Build service account the permissions to execute BigQuery jobs","04-12"
"pubsub-setting-up-dataflow-config.png","Setting up a Dataflow from within the Google Cloud Console for a PubSub topic into BigQuery via the pre-defined template","04-13"
"dataflow-running.png","Starting up a running job for importing PubSub messages into BigQuery in real-time","04-14"
"pubsub-dataflow-bigquery-schema.png","The BigQuery data schema to receive the PubSub Json","04-15"
"pubsub-dataflow-bigquery-errors.png","Any errors from the data flow will appear in its own BigQuery table so you can examine the payloads","04-16"
"pubsub-dataflow-bigquery.png","A successful streaming import from GA4 into GTM-SS to PubSub to BigQuery","04-17"
"pubsub-to-bq-env-args.png","Setting the environment arguments for use within the cloud function","04-18"
"pubsub-to-bq-parse-json.png","The raw data table receiving the PubSub stream from GA4 via GTM-SS can have its JSON parsed out with BigQuery's functions such as JSON_VALUE()","04-19"
"bigquery-dataset-table-expiration.png","You can configure the table expiration time when you create a dataset","04-20"
"ga4-attribution.png","In GA4 you can set attribution settings on how your conversions are attributed to which channel","05-01"
"ga4-reporting-id.png","Selecting how users can be identified within GA4 reports","05-02"
"lowest-channel.png","Writing questions in the GA4 search bar will parse itself to try and find the most appropriate GA4 report for you","05-03"
"insights-ga4.png","Insights looks to flag the most important findings of the day when you log in","05-04"
"bq-model-cheatsheet.png","This cheat sheet shows what use cases and BigQuery ML model may be most appropriate","05-05"
"nlp-pipeline.png","An event based pipeline for processing text files on Cloud Storage as they arrive and put the Natural Language API results into a BigQuery table","05-06"
"vertex-ai-dataset.png","Creating a dataset from BigQuery in Vertex AI","05-07"
"ga4-demo-audience-list.png","A list of GA4 Audiences taken from the GA4 demo account for Google Merchandise Store","06-01"
"audience-session-start-2-pvs.png","A configuration for session_start events with 2 further page_view events.","06-02"
"audience-got-not-open.png","A configuration for users who received a notification but did not open it","06-03"
"suggested-predictive-audiences.png","If you fulfil the criteria you will see predictive audiences available in your GA4 configuration","06-04"
"optimise-target-audience.png","Selecting a GA4 audience within Google Optimise","06-05"
"optimise-banner.png","Setting up a banner for the website that will trigger when the GA4 Audience segment is fulfilled.","06-06"
"ga4-reports-trend.png","GA4 Standard Reports show you real-time updates and trends for your GA4 event data","06-07"
"image:images/ga4-user-acquisition.png[Showing how users first arrived to my blog]","image:images/ga4-user-acquisition.png[Showing how users first arrived to my blog]","06-08"
"ga4-select-goal-event.png","Selecting which of your events or goal conversions that channel contributed to","06-09"
"ga4-segment-comparisons.png","Comparison of All Users and users who arrived via Google for the count of google analytics category articles","06-10"
"ga4-merchandise-anomaly.png","An anomaly spike found in the merchandise data within the Google Merchandise Store demo GA$ account","06-11"
"ga4-customise-collection.png","A custom collection of reports for my Blog","06-12"
"ga4-explorations.png","The start of your Exploration work flow involves selecting or creating one from the start screen","06-13"
"ga4-explorations-select-variables.png","Select the variables you think you will need in your exploration","06-14"
"ga4-explorations-segments.png","Using the Segment overlap technique to see which users are from the US and use mobile devices","06-15"
"ga4-exploration-fields.png","Selecting the appropriate fields for your exploration report","06-16"
"ga4-exploration-user-explorer.png","The User Explorer report can drill down on an individual cookie ID","06-17"
"ga4-pathing.png","Path analysis of which pages were visited after the two_pageviews event was triggered","06-18"
"ga4-funnels.png","Examining a funnel drop-out journey","06-19"
"ga4-cohorts.png","How many users who triggered the googleanalytics_viewer event came back to the website the subsequent months","06-20"
"datastudio-connectors.png","Connecting Data Studio to GA4","06-21"
"gar-data-studio-connectors.png","Connecting Data Studio via the Google Analytics connector vs the BigQuery table","06-22"
"ga4-datastudio-databloo.png","A GA4 Data Studio example for GA4 from Databloo","06-23"
"ga4_looker.jpg","Looker connects to GA4's BigQuery dataset and uses its LookML language to create useful data points","06-24"
"form_submit_to_pubsub.png","The tag within GTM-SS for forwarding on your events to a HTTP endpoint","06-25"
"firestore-example.png","Example data within a Firestore instance","06-26"
"firestore-lookup-gtmss.png","A Firestore Lookup Variable in Google Tag Manager Serverside","06-27"
"data-architecture-7.png","Data Architecture for the Predictive Audiences use case:  website data is sent to Google Analytics 4 which creates the predictive audience that is then exported to Google Ads","07-01"
"audience-creation.png","Customising a predictive audience","07-02"
"predicitve-audeince-config.png","Configuration of an Audience showing likely purchasers in the next seven days","07-03"
"chapter8_predictive.drawio.png","Data Architecture for the User Segmentation use case","08-01"
"user_profession_08.png","Configuration of a custom field to hold user profession in GA4","08-02"
"fake-crm-data-08.png","Fake CRM data  within BigQuery generated to overlap the Google Merchandise Store cookieIds","08-03"
"sql-example-8-ga4-screenshot.png","The results of a transaction query upon the public GA4 data","08-04"
"ga4-crm-join-result-08.png","An example showing the result of joining the demo datasets from GA4 and CRM","08-05"
"firestore-crm-import.png","Your CRM data imported into Firestore from BigQuery","08-06"
"ga4-gtm-ss-user-id.png","Setting up a custom event to extract the user_id we will use as the document name to fetch data from Firestore","08-07"
"ga4-gtm-ss-job.png","Configuring a GTM-SS Firestore Lookup variable so call our Firestore collection containing the CRM data, using user_id as its document reference","08-08"
"ga4-gtm-ss-tag.png","Configuring a GA4 GTM-SS event tag with user properties adding the Firestore value","08-09"
"doctors-who-may-purchase.png","Adding a new custom dimension to our Audience definitions, that will combine with the existing Predictive Audience","08-10"
"predicitve-audeince-config.png","Configuration of an Audience showing likely purchasers in the next seven days","08-11"
"data-architecture-chapter_09.png","Real-time data is taken from GA4 and a forecast is created to inform employee what content they should prioritise for social media content and on-site banners via Google Optimise","09-01"
"medical-users-medical-content-audiences.png","Creating an audience we can query in the Real-Time API matching /medical-books to users who are Doctors","09-02"
"medical-users-medical-content-event-trigger.png","When users qualify for the audience, they can set off an event that can be seen within the Real-Time API","09-03"
"cloud-run-container.png","The Container Image URL will be the one you have specified for your local Docker build","09-04"
"r-forecasts.png","Some example output for forecasting GA4 real-time Audience data","09-05"
"r-highcharter.png","Output from the script that turns R forecast objects into `www.highcharts.com` plots","09-06"
"create-service-key-for-ga4.png","Create a service key for use within your app","09-07"
"create-new-json-key.png","Once you have created the service account, download a JSON key for use within your application","09-08"
"adding-service-account-ga4.png","Adding a service email as a user to the GA4 interface for use within your scripts","09-09"
"ga4-realtime-shiny-app.png","A running Shiny app with real-time GA4 data and a forecast","09-10"
